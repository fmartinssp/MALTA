{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3143373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries import\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from numpy import empty\n",
    "import sklearn.metrics as metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "%run evaluation/metrics.ipynb\n",
    "\n",
    "\"\"\"Perform classification models on data.\n",
    "\n",
    "    Args:\n",
    "      model: Classifier.\n",
    "      data: dataset (dataframe).\n",
    "      folds: Number of folds to perform cross validation.\n",
    "\"\"\"\n",
    "\n",
    "def classifiers(model, data, folds, imp_name, dataset_name, mech):\n",
    "    os.chdir(f\"C:\\Anaconda3\\Scripts\\MALTA\\src\")\n",
    "    kf = KFold(n_splits=folds)\n",
    "    best = 0\n",
    "    \n",
    "    #Get the input features\n",
    "    columns = data.columns\n",
    "    class_name = columns[-1] #Get name of the last column (class)\n",
    "    columns_tmp = list(columns)\n",
    "    columns_tmp.remove(class_name)\n",
    "\n",
    "    #Get the number of classes\n",
    "    num_classes = np.size(data[class_name].unique())\n",
    "    \n",
    "    x, x_test, y, y_test = train_test_split(data[columns_tmp], data[class_name], test_size=0.1)\n",
    "\n",
    "    fold = 1\n",
    "\n",
    "    #precision_valid = np.array([])\n",
    "    #recall_valid = np.array([])\n",
    "    #fscore_valid = np.array([])\n",
    "    \n",
    "    precision_valid = empty(num_classes)\n",
    "    recall_valid = empty(num_classes)\n",
    "    fscore_valid = empty(num_classes)\n",
    "    fscore_interval = [] #List used to calculate the confidence interval in cross-validation \n",
    "\n",
    "    for train_index, valid_index in kf.split(x):\n",
    "            x_train = x.iloc[train_index].loc[:]\n",
    "            y_train = y.iloc[train_index]\n",
    "\n",
    "            x_valid = x.iloc[valid_index].loc[:]\n",
    "            y_valid = y.iloc[valid_index]\n",
    "\n",
    "            #Model training and validation\n",
    "            model.fit(x_train, y_train)\n",
    "            predict = model.predict(x_valid)\n",
    "\n",
    "            \n",
    "            #Computing the metrics\n",
    "            precision,recall,fscore,support = classifier_metrics(y_valid, predict)\n",
    "\n",
    "            #precision_valid = np.append(precision_valid, precision, axis=None)\n",
    "            #recall_valid = np.append(recall_valid, precision, axis=None)\n",
    "            #fscore_valid = np.append(fscore_valid, precision, axis=None)\n",
    "            #print(precision_valid)\n",
    "\n",
    "            if (precision.shape != precision_valid.shape):\n",
    "                # redimensionando o segundo dataframe para a nova forma\n",
    "                precision = np.resize(precision, precision_valid.shape)\n",
    "                        \n",
    "            if (recall.shape != recall_valid.shape):\n",
    "                # redimensionando o segundo dataframe para a nova forma\n",
    "                recall = np.resize(recall, recall_valid.shape)\n",
    "                \n",
    "            if (fscore.shape != fscore_valid.shape):\n",
    "                # redimensionando o segundo dataframe para a nova forma\n",
    "                fscore = np.resize(fscore, fscore_valid.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "            precision_valid = np.add(precision_valid,precision)\n",
    "            recall_valid = np.add(recall_valid,recall)\n",
    "            fscore_valid = np.add(fscore_valid,fscore) \n",
    "            print(\"F1 Score valid: \", fscore_valid)\n",
    "                    \n",
    "            fscore_interval.append(mean_fscore(fscore)) #Append metrics for confidence interval calculation\n",
    "            \n",
    "            #Get the best model from cross-validation\n",
    "            accuracy = np.mean(y_valid == predict)\n",
    "            if accuracy > best:          \n",
    "                best = accuracy\n",
    "                best_model = copy.deepcopy(model)\n",
    "\n",
    "            fold += 1\n",
    "    \n",
    "    \n",
    "    print('---------------------------- Model ---------------------------------')\n",
    "    print(model)\n",
    "    print('--------------------------------------------------------------------')\n",
    "\n",
    "    print('------------------ Cross Validation Results ------------------------')  \n",
    "    print('--------------------------------------------------------------------')\n",
    "        \n",
    "    precisionV = pd.Series(np.round(precision_valid/folds,num_classes))\n",
    "    recallV = pd.Series(np.round(recall_valid/folds,num_classes))\n",
    "    fscoreV = pd.Series(np.round(fscore_valid/folds,num_classes))\n",
    "    \n",
    "    precision_valid = np.zeros(precision_valid.shape)\n",
    "    recall_valid = np.zeros(recall_valid.shape)\n",
    "    fscore_valid = np.zeros(fscore_valid.shape)\n",
    "      \n",
    "    valid_result = pd.concat([(pd.concat([precisionV, recallV], axis=1)), fscoreV], axis = 1)\n",
    "    valid_result.columns = ['Precision', 'Recall', 'F1 Score']\n",
    "    print(valid_result)\n",
    "    \n",
    "    model_name = type(model).__name__\n",
    "    \n",
    "    file = f'reports/classifiers_results/{dataset_name}/{imp_name}/valid_' + model_name + '_' + imp_name + '_' + mech + '.csv'\n",
    "    if (os.path.exists(file)):\n",
    "        result_p = pd.read_csv(f'reports/classifiers_results/{dataset_name}/{imp_name}/valid_' + model_name + '_' + imp_name + '_' + mech + '.csv', sep=';', error_bad_lines=False, encoding=\"latin-1\")\n",
    "        valid_result = pd.concat([result_p, valid_result], axis = 1)\n",
    "    \n",
    "    valid_result.to_csv(f'reports/classifiers_results/{dataset_name}/{imp_name}/valid_' + model_name + '_' + imp_name + '_' + mech + '.csv', sep=';',index=False)\n",
    " \n",
    "    precision_valid = np.array([])\n",
    "    recall_valid = np.array([])\n",
    "    fscore_valid = np.array([])\n",
    "\n",
    "    print('--------------------------------------------------------------------')\n",
    "    print('------------ 95% Confidence Interval Result - F1 Score -----------------')  \n",
    "    print('--------------------------------------------------------------------')\n",
    "    print(interval_confidence(fscore_interval)) \n",
    "\n",
    "\n",
    "    \n",
    "    print('--------------------------------------------------------------------')\n",
    "\n",
    "    print('----------------------- Tests Results-------------------------------')\n",
    "    print('--------------------------------------------------------------------')      \n",
    "    p = best_model.predict(x_test) #Test with the best model from cross-validation\n",
    "    \n",
    "    metrics_summary = precision_recall_fscore_support(y_test, p, average=None)\n",
    "        \n",
    "    precisionT = pd.Series(np.round(metrics_summary[0],num_classes))\n",
    "    recallT = pd.Series(np.round(metrics_summary[1],num_classes))\n",
    "    fscoreT = pd.Series(np.round(metrics_summary[2],num_classes))\n",
    "    \n",
    "    test_result = pd.concat([(pd.concat([precisionT, recallT], axis=1)), fscoreT], axis = 1)\n",
    "    test_result.columns = ['Precision', 'Recall', 'F1 Score']\n",
    "    print(test_result)\n",
    "    \n",
    "    file = f'reports/classifiers_results/{dataset_name}/{imp_name}/test_' + model_name + '_' + imp_name + '_' + mech + '.csv'\n",
    "    #Check if csv file already exists\n",
    "    if (os.path.exists(file)):\n",
    "        result_p = pd.read_csv( f'reports/classifiers_results/{dataset_name}/{imp_name}/test_' + model_name + '_' + imp_name + '_' + mech + '.csv', sep=';', error_bad_lines=False, encoding=\"latin-1\")\n",
    "        test_result = pd.concat([result_p, test_result], axis = 1) \n",
    "  \n",
    "    test_result.to_csv( f'reports/classifiers_results/{dataset_name}/{imp_name}/test_' + model_name + '_' + imp_name + '_' + mech + '.csv', sep=';',index=False)\n",
    "    \n",
    "    print('--------------------------------------------------------------------')\n",
    "    \n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05edfc6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
